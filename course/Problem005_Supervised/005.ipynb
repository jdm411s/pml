{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "005.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdWgY7LfL_kK"
      },
      "source": [
        "## Supervised Learning - Regression\n",
        "\n",
        "*y* is a real number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "aL2yyxvpL_kL",
        "outputId": "306ecc85-8af3-44e0-9d39-17b929929f15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn import linear_model\n",
        "'''\n",
        "+--------------+\n",
        "| frev         |\n",
        "+--------------+\n",
        "| x1 | x2 | y  |\n",
        "+----+----+----+\n",
        "| 2  | 3  | 4  |\n",
        "+----+----+----+\n",
        "| 8  | 5  | 9  |\n",
        "+----+----+----+\n",
        "| 6  | 4  | 7  |\n",
        "+----+----+----+\n",
        "| 10 | 2  | 7  |\n",
        "+----+----+----+\n",
        "| 4  | 2  | 4  |\n",
        "+----+----+----+\n",
        "| 16 | 7  | 15 |\n",
        "+----+----+----+\n",
        "'''\n",
        "model = linear_model.LinearRegression()\n",
        "\n",
        "X = [\n",
        "     [2,3],\n",
        "     [8,5],\n",
        "     [6,4],\n",
        "     [10,2],\n",
        "     [4,2],\n",
        "     [16,7],\n",
        "]\n",
        "\n",
        "Y = [4,9,7,7,4,15]\n",
        "\n",
        "#TBD: Fit/Train the model from observed data\n",
        "model.fit(X, Y)\n",
        "\n",
        "#TBD: Use fitted/trained model to predict for any given x1, x2\n",
        "model.predict([[8,8],[4,2]])\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12.,  4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiaMW_4HL_kQ"
      },
      "source": [
        "## Supervised Learning - Classification\n",
        "*y* is a class/category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxeFxNzBL_kQ",
        "outputId": "55f8450e-3c87-41df-f789-4240cceb0acc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model.logistic import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "'''\n",
        "Building a labelled dataset of documents\n",
        "'''\n",
        "doc0 = \"hello world\"\n",
        "doc1 = \"foo bar\"\n",
        "doc2 = \"lottery prize winner\"\n",
        "docs_train = [doc0] * 1000 + [doc1] * 1000 + [doc2] * 400 \n",
        "\n",
        "\n",
        "'''\n",
        "    Converting documents to feature vectors\n",
        "'''\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
        "X_train = vectorizer.fit_transform(docs_train).toarray()\n",
        "Y_train = np.array([[0] * 1000 + [0] * 1000 + [1.0] * 400]).reshape(2400,)\n",
        "features = vectorizer.get_feature_names()\n",
        "print(f'Features: {features}')\n",
        "\n",
        "'''\n",
        "Choosing the model\n",
        "'''\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "\n",
        "'''\n",
        "    Train the model\n",
        "'''\n",
        "#TBD Fit the model to training data\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "'''\n",
        "    Test the model\n",
        "'''\n",
        "#TBD Use fitted model to predict if the documents in test data are spam or not\n",
        "docs_test = [\n",
        "             \"lottery winner\",\n",
        "             \"hello foo\", \n",
        "             \"hello bar\", \n",
        "             \"lottery prize\", \n",
        "             \"world foo\",\n",
        "             \"prize winner\",\n",
        "            ]\n",
        "\n",
        "X_test = vectorizer.transform(docs_test).toarray()\n",
        "\n",
        "predictions = classifier.predict(X_test)\n",
        "print(f'Spam classification (1 means document is spam):\\n====\\n{predictions}\\n====\\n')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features: ['bar', 'foo', 'foo bar', 'hello', 'hello world', 'lottery', 'lottery prize', 'prize', 'prize winner', 'winner', 'world']\n",
            "Spam classification (1 means document is spam):\n",
            "====\n",
            "[0. 0. 0. 1. 0. 1.]\n",
            "====\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UiIVjjVOo9P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}